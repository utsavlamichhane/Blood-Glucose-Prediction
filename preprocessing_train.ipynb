{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66683068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518129/3279662898.py:4: DtypeWarning: Columns (435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"train.csv\")\n",
      "/tmp/ipykernel_518129/3279662898.py:14: DtypeWarning: Columns (435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique values in activity columns: 23\n",
      "Unique values in activity columns:\n",
      "[nan 'Walk' 'Indoor climbing' 'Yoga' 'Zumba' 'HIIT' 'Dancing' 'Swim'\n",
      " 'Outdoor Bike' 'Aerobic Workout' 'Sport' 'Walking' 'Running' 'Swimming'\n",
      " 'Run' 'Weights' 'Workout' 'Tennis' 'Strength training' 'Stairclimber'\n",
      " 'Spinning' 'Hike' 'Bike']\n",
      "   activity-5:55  activity-5:50  activity-5:45  activity-5:40  activity-5:35  \\\n",
      "0            0.0            0.0            0.0            0.0            0.0   \n",
      "1            0.0            0.0            0.0            0.0            0.0   \n",
      "2            0.0            0.0            0.0            0.0            0.0   \n",
      "3            0.0            0.0            0.0            0.0            0.0   \n",
      "4            0.0            0.0            0.0            0.0            0.0   \n",
      "\n",
      "   activity-5:30  activity-5:25  activity-5:20  activity-5:15  activity-5:10  \\\n",
      "0            0.0            0.0            0.0            0.0            0.0   \n",
      "1            0.0            0.0            0.0            0.0            0.0   \n",
      "2            0.0            0.0            0.0            0.0            0.0   \n",
      "3            0.0            0.0            0.0            0.0            0.0   \n",
      "4            0.0            0.0            0.0            0.0            0.0   \n",
      "\n",
      "   ...  activity-0:45  activity-0:40  activity-0:35  activity-0:30  \\\n",
      "0  ...            0.0            0.0            0.0            0.0   \n",
      "1  ...            0.0            0.0            0.0            0.0   \n",
      "2  ...            0.0            0.0            0.0            0.0   \n",
      "3  ...            0.0            0.0            0.0            0.0   \n",
      "4  ...            0.0            0.0            0.0            0.0   \n",
      "\n",
      "   activity-0:25  activity-0:20  activity-0:15  activity-0:10  activity-0:05  \\\n",
      "0            0.0            0.0            0.0            0.0            0.0   \n",
      "1            0.0            0.0            0.0            0.0            0.0   \n",
      "2            0.0            0.0            0.0            0.0            0.0   \n",
      "3            0.0            0.0            0.0            0.0            0.0   \n",
      "4            0.0            0.0            0.0            0.0            0.0   \n",
      "\n",
      "   activity-0:00  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "\n",
      "[5 rows x 72 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518129/3279662898.py:76: DtypeWarning: Columns (435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id p_num      time  bg-5:55  bg-5:50  bg-5:45  bg-5:40  bg-5:35  \\\n",
      "0  p01_0   p01  06:10:00      NaN      NaN      9.6      NaN      NaN   \n",
      "1  p01_1   p01  06:25:00      NaN      NaN      9.7      NaN      NaN   \n",
      "2  p01_2   p01  06:40:00      NaN      NaN      9.2      NaN      NaN   \n",
      "3  p01_3   p01  06:55:00      NaN      NaN      8.7      NaN      NaN   \n",
      "4  p01_4   p01  07:10:00      NaN      NaN      8.4      NaN      NaN   \n",
      "\n",
      "   bg-5:30  bg-5:25  ...  cals-0:35  cals-0:30  cals-0:25  cals-0:20  \\\n",
      "0      9.7      NaN  ...        NaN        NaN        NaN        NaN   \n",
      "1      9.2      NaN  ...        NaN        NaN        NaN        NaN   \n",
      "2      8.7      NaN  ...        NaN        NaN        NaN        NaN   \n",
      "3      8.4      NaN  ...        NaN        NaN        NaN        NaN   \n",
      "4      8.1      NaN  ...        NaN        NaN        NaN        NaN   \n",
      "\n",
      "   cals-0:15  cals-0:10  cals-0:05  cals-0:00  target  activity_score  \n",
      "0        NaN        NaN        NaN        NaN    13.4             0.0  \n",
      "1        NaN        NaN        NaN        NaN    12.8             0.0  \n",
      "2        NaN        NaN        NaN        NaN    15.5             0.0  \n",
      "3        NaN        NaN        NaN        NaN    14.8             0.0  \n",
      "4        NaN        NaN        NaN        NaN    12.7             0.0  \n",
      "\n",
      "[5 rows x 437 columns]\n",
      "      id p_num      time  bg-5:55  bg-5:50  bg-5:45  bg-5:40  bg-5:35  \\\n",
      "0  p01_0   p01  06:10:00      NaN      NaN      9.6      NaN      NaN   \n",
      "1  p01_1   p01  06:25:00      NaN      NaN      9.7      NaN      NaN   \n",
      "2  p01_2   p01  06:40:00      NaN      NaN      9.2      NaN      NaN   \n",
      "3  p01_3   p01  06:55:00      NaN      NaN      8.7      NaN      NaN   \n",
      "4  p01_4   p01  07:10:00      NaN      NaN      8.4      NaN      NaN   \n",
      "\n",
      "   bg-5:30  bg-5:25  ...  carbs_carbs-2:25_to_carbs-2:15  \\\n",
      "0      9.7      NaN  ...                             0.0   \n",
      "1      9.2      NaN  ...                             0.0   \n",
      "2      8.7      NaN  ...                             0.0   \n",
      "3      8.4      NaN  ...                             0.0   \n",
      "4      8.1      NaN  ...                             0.0   \n",
      "\n",
      "   carbs_carbs-2:10_to_carbs-2:00  carbs_carbs-1:55_to_carbs-1:45  \\\n",
      "0                             0.0                             0.0   \n",
      "1                             0.0                             0.0   \n",
      "2                             0.0                             0.0   \n",
      "3                             0.0                             0.0   \n",
      "4                             0.0                             0.0   \n",
      "\n",
      "   carbs_carbs-1:40_to_carbs-1:30  carbs_carbs-1:25_to_carbs-1:15  \\\n",
      "0                             0.0                             0.0   \n",
      "1                             0.0                             0.0   \n",
      "2                             0.0                             0.0   \n",
      "3                             0.0                             0.0   \n",
      "4                             0.0                             0.0   \n",
      "\n",
      "   carbs_carbs-1:10_to_carbs-1:00  carbs_carbs-0:55_to_carbs-0:45  \\\n",
      "0                             0.0                             0.0   \n",
      "1                             0.0                             0.0   \n",
      "2                             0.0                             0.0   \n",
      "3                             0.0                             0.0   \n",
      "4                             0.0                             0.0   \n",
      "\n",
      "   carbs_carbs-0:40_to_carbs-0:30  carbs_carbs-0:25_to_carbs-0:15  \\\n",
      "0                             0.0                             0.0   \n",
      "1                             0.0                             0.0   \n",
      "2                             0.0                             0.0   \n",
      "3                             0.0                             0.0   \n",
      "4                             0.0                             0.0   \n",
      "\n",
      "   carbs_carbs-0:10_to_carbs-0:00  \n",
      "0                             0.0  \n",
      "1                             0.0  \n",
      "2                             0.0  \n",
      "3                             0.0  \n",
      "4                             0.0  \n",
      "\n",
      "[5 rows x 389 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
      "/tmp/ipykernel_518129/3279662898.py:176: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id p_num      time  bg-5:55  bg-5:50  bg-5:45  bg-5:40  bg-5:35  \\\n",
      "0  p01_0   p01  06:10:00      NaN      NaN      9.6      NaN      NaN   \n",
      "1  p01_1   p01  06:25:00      NaN      NaN      9.7      NaN      NaN   \n",
      "2  p01_2   p01  06:40:00      NaN      NaN      9.2      NaN      NaN   \n",
      "3  p01_3   p01  06:55:00      NaN      NaN      8.7      NaN      NaN   \n",
      "4  p01_4   p01  07:10:00      NaN      NaN      8.4      NaN      NaN   \n",
      "\n",
      "   bg-5:30  bg-5:25  ...  steps_from_steps-2:25_to_steps-2:15  \\\n",
      "0      9.7      NaN  ...                                  0.0   \n",
      "1      9.2      NaN  ...                                  0.0   \n",
      "2      8.7      NaN  ...                                  0.0   \n",
      "3      8.4      NaN  ...                                  0.0   \n",
      "4      8.1      NaN  ...                                  0.0   \n",
      "\n",
      "   steps_from_steps-2:10_to_steps-2:00  steps_from_steps-1:55_to_steps-1:45  \\\n",
      "0                                  0.0                                  0.0   \n",
      "1                                  0.0                                  0.0   \n",
      "2                                  0.0                                  0.0   \n",
      "3                                  0.0                                  0.0   \n",
      "4                                  0.0                                  0.0   \n",
      "\n",
      "   steps_from_steps-1:40_to_steps-1:30  steps_from_steps-1:25_to_steps-1:15  \\\n",
      "0                                  0.0                                  0.0   \n",
      "1                                  0.0                                  0.0   \n",
      "2                                  0.0                                  0.0   \n",
      "3                                  0.0                                  0.0   \n",
      "4                                  0.0                                  0.0   \n",
      "\n",
      "   steps_from_steps-1:10_to_steps-1:00  steps_from_steps-0:55_to_steps-0:45  \\\n",
      "0                                  0.0                                  0.0   \n",
      "1                                  0.0                                  0.0   \n",
      "2                                  0.0                                  0.0   \n",
      "3                                  0.0                                  0.0   \n",
      "4                                  0.0                                  0.0   \n",
      "\n",
      "   steps_from_steps-0:40_to_steps-0:30  steps_from_steps-0:25_to_steps-0:15  \\\n",
      "0                                  0.0                                  0.0   \n",
      "1                                  0.0                                  0.0   \n",
      "2                                  0.0                                  0.0   \n",
      "3                                  0.0                                  0.0   \n",
      "4                                  0.0                                  0.0   \n",
      "\n",
      "   steps_from_steps-0:10_to_steps-0:00  \n",
      "0                                  0.0  \n",
      "1                                  0.0  \n",
      "2                                  0.0  \n",
      "3                                  0.0  \n",
      "4                                  0.0  \n",
      "\n",
      "[5 rows x 293 columns]\n",
      "bg-5:55    0\n",
      "bg-5:50    0\n",
      "bg-5:45    0\n",
      "bg-5:40    0\n",
      "bg-5:35    0\n",
      "          ..\n",
      "bg-0:20    0\n",
      "bg-0:15    0\n",
      "bg-0:10    0\n",
      "bg-0:05    0\n",
      "bg-0:00    0\n",
      "Length: 72, dtype: int64\n",
      "hr-5:55    0\n",
      "hr-5:50    0\n",
      "hr-5:45    0\n",
      "hr-5:40    0\n",
      "hr-5:35    0\n",
      "          ..\n",
      "hr-0:20    0\n",
      "hr-0:15    0\n",
      "hr-0:10    0\n",
      "hr-0:05    0\n",
      "hr-0:00    0\n",
      "Length: 72, dtype: int64\n",
      "     hr-5:55    hr-5:50    hr-5:45    hr-5:40    hr-5:35    hr-5:30  \\\n",
      "0  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "1  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "2  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "3  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "4  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "\n",
      "     hr-5:25    hr-5:20    hr-5:15    hr-5:10  ...    hr-0:45    hr-0:40  \\\n",
      "0  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "1  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "2  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "3  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "4  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "\n",
      "     hr-0:35    hr-0:30    hr-0:25    hr-0:20    hr-0:15    hr-0:10  \\\n",
      "0  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "1  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "2  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "3  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "4  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "\n",
      "     hr-0:05    hr-0:00  \n",
      "0  79.333098  79.335216  \n",
      "1  79.333098  79.335216  \n",
      "2  79.333098  79.335216  \n",
      "3  79.333098  79.335216  \n",
      "4  79.333098  79.335216  \n",
      "\n",
      "[5 rows x 72 columns]\n",
      "insulin-5:55    9446\n",
      "insulin-5:50    9445\n",
      "insulin-5:45    9444\n",
      "insulin-5:40    9443\n",
      "insulin-5:35    9442\n",
      "                ... \n",
      "insulin-0:20    9379\n",
      "insulin-0:15    9378\n",
      "insulin-0:10    9377\n",
      "insulin-0:05    9376\n",
      "insulin-0:00    9375\n",
      "Length: 72, dtype: int64\n",
      "Total missing values in insulin columns: 677556\n",
      "Remaining missing values after imputation: insulin-5:55    0\n",
      "insulin-5:50    0\n",
      "insulin-5:45    0\n",
      "insulin-5:40    0\n",
      "insulin-5:35    0\n",
      "               ..\n",
      "insulin-0:20    0\n",
      "insulin-0:15    0\n",
      "insulin-0:10    0\n",
      "insulin-0:05    0\n",
      "insulin-0:00    0\n",
      "Length: 72, dtype: int64\n",
      "   insulin-5:55  insulin-5:50  insulin-5:45  insulin-5:40  insulin-5:35  \\\n",
      "0        0.0083        0.0083        0.0083        0.0083        0.0083   \n",
      "1        0.0083        0.0083        0.0083        0.0083        0.0083   \n",
      "2        0.0083        0.0083        0.0083        0.0083        0.0083   \n",
      "3        0.0083        0.0083        0.0083        0.0083        0.0083   \n",
      "4        0.0083        0.0083        0.0083        0.0083        0.0083   \n",
      "\n",
      "   insulin-5:30  insulin-5:25  insulin-5:20  insulin-5:15  insulin-5:10  ...  \\\n",
      "0        0.0083        0.0083        0.0083        0.0083        0.0083  ...   \n",
      "1        0.0083        0.0083        0.0083        0.0083        0.0083  ...   \n",
      "2        0.0083        0.0083        0.0083        0.0083        0.0083  ...   \n",
      "3        0.0083        0.0083        0.0083        0.0083        0.0083  ...   \n",
      "4        0.0083        0.0083        0.0083        0.0083        0.0083  ...   \n",
      "\n",
      "   insulin-0:45  insulin-0:40  insulin-0:35  insulin-0:30  insulin-0:25  \\\n",
      "0        0.0583        0.0583        0.0583        0.0583        0.0583   \n",
      "1        0.0583        0.0583        0.0583        0.0583        0.0583   \n",
      "2        0.0583        0.0583        0.0417        0.0417        0.0417   \n",
      "3        0.0417        0.0417        0.0417        0.0417        0.0417   \n",
      "4        0.0417        0.0417        0.0417        0.0417        0.0417   \n",
      "\n",
      "   insulin-0:20  insulin-0:15  insulin-0:10  insulin-0:05  insulin-0:00  \n",
      "0        0.0583        0.0583        0.0583        0.0417        0.0417  \n",
      "1        0.0417        0.0417        0.0417        0.0417        0.0417  \n",
      "2        0.0417        0.0417        0.0417        0.0417        0.0417  \n",
      "3        0.0417        0.0417        0.0417        0.0417        0.0417  \n",
      "4        0.0417        0.0417        0.0417        0.0417        0.0417  \n",
      "\n",
      "[5 rows x 72 columns]\n",
      "insulin-5:55    0.195128\n",
      "insulin-5:50    0.195373\n",
      "insulin-5:45    0.194237\n",
      "insulin-5:40    0.194374\n",
      "insulin-5:35    0.194544\n",
      "                  ...   \n",
      "insulin-0:20    0.205639\n",
      "insulin-0:15    0.204215\n",
      "insulin-0:10    0.200293\n",
      "insulin-0:05    0.198332\n",
      "insulin-0:00    0.196335\n",
      "Length: 72, dtype: float64\n",
      "hr-5:55    0\n",
      "hr-5:50    0\n",
      "hr-5:45    0\n",
      "hr-5:40    0\n",
      "hr-5:35    0\n",
      "          ..\n",
      "hr-0:20    0\n",
      "hr-0:15    0\n",
      "hr-0:10    0\n",
      "hr-0:05    0\n",
      "hr-0:00    0\n",
      "Length: 72, dtype: int64\n",
      "     hr-5:55    hr-5:50    hr-5:45    hr-5:40    hr-5:35    hr-5:30  \\\n",
      "0  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "1  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "2  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "3  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "4  79.296328  79.296743  79.294168  79.297492  79.303325  79.300169   \n",
      "\n",
      "     hr-5:25    hr-5:20    hr-5:15    hr-5:10  ...    hr-0:45    hr-0:40  \\\n",
      "0  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "1  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "2  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "3  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "4  79.305288  79.310368  79.303847  79.307078  ...  79.317773  79.320335   \n",
      "\n",
      "     hr-0:35    hr-0:30    hr-0:25    hr-0:20    hr-0:15    hr-0:10  \\\n",
      "0  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "1  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "2  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "3  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "4  79.320997  79.321206  79.324963  79.326971  79.329691  79.330054   \n",
      "\n",
      "     hr-0:05    hr-0:00  \n",
      "0  79.333098  79.335216  \n",
      "1  79.333098  79.335216  \n",
      "2  79.333098  79.335216  \n",
      "3  79.333098  79.335216  \n",
      "4  79.333098  79.335216  \n",
      "\n",
      "[5 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#given_training_data_set\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "#target\n",
    "#rename the 'bg+1:00' column to 'target'\n",
    "df.rename(columns={'bg+1:00': 'target'}, inplace=True)\n",
    "\n",
    "\n",
    "#i tend to save the df after each step in my preprocessing so that I can debug from the point, not the entire ds\n",
    "###\n",
    "####DataFrame to a new CSV file\n",
    "file_path = 'train_bg_renamed.csv'\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "#just to see the new df \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#activity columns\n",
    "activity_cols = [col for col in df.columns if col.startswith('activity-')]\n",
    "\n",
    "#unique values from all activity columns\n",
    "unique_values = pd.unique(df[activity_cols].values.ravel('K'))\n",
    "\n",
    "#total number of unique values\n",
    "print(f\"Total number of unique values in activity columns: {len(unique_values)}\")\n",
    "\n",
    "# Print the list of unique values\n",
    "print(\"Unique values in activity columns:\")\n",
    "print(unique_values)\n",
    "\n",
    "#here i mapped the different activity based on their intensity,\n",
    "###like the walking is less intense then the running, so wal is mapped to numerial value of 3 and run as 8\n",
    "#the activity-to-intensity mapping\n",
    "activity_intensity_mapping = {\n",
    "    'Walk': 3,\n",
    "    'Indoor climbing': 3,\n",
    "    'Yoga': 2,\n",
    "    'Zumba': 7,\n",
    "    'HIIT': 9,\n",
    "    'Dancing': 3,\n",
    "    'Swim': 7,\n",
    "    'Outdoor Bike': 5,\n",
    "    'Aerobic Workout': 6,\n",
    "    'Sport': 5,\n",
    "    'Walking': 3,\n",
    "    'Running': 8,\n",
    "    'Swimming': 7,\n",
    "    'Run': 8,\n",
    "    'Weights': 4,\n",
    "    'Workout': 5,\n",
    "    'Tennis': 6,\n",
    "    'Strength training': 5,\n",
    "    'Stairclimber': 6,\n",
    "    'Spinning': 6,\n",
    "    'Hike': 7,\n",
    "    'Bike': 7\n",
    "}\n",
    "\n",
    "####cols\n",
    "activity_cols = [col for col in df.columns if col.startswith('activity-')]\n",
    "\n",
    "##replacing the intensity score by their map\n",
    "df[activity_cols] = df[activity_cols].replace(activity_intensity_mapping)\n",
    "\n",
    "#replacing if any zerros here\n",
    "df[activity_cols] = df[activity_cols].fillna(0)\n",
    "\n",
    "for col in activity_cols:\n",
    "    if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "        print(f\"Dropped column '{col}' due to non-numeric values.\")\n",
    "\n",
    "\n",
    "#one activity_col_representing_all mapped score        \n",
    "df['activity_score'] = df[activity_cols].sum(axis=1)\n",
    "\n",
    "# dropping all, keeping only 'activity_score'\n",
    "df.drop(columns=activity_cols, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "####   new CSV file\n",
    "df.to_csv('train_with_activity_score.csv', index=False)\n",
    "\n",
    "####okkk lets look if the str is replaced by the int\n",
    "print(df[activity_cols].head())\n",
    "\n",
    "\n",
    "######lets see againnn\n",
    "df\n",
    "\n",
    "\n",
    "####latest csv from yesterday (same dir: mac/from_sapelo2/kaggle/glucose_pred/preprocessing_oct_28.ipynb)\n",
    "#\n",
    "#\n",
    "####\n",
    "###\n",
    "file_path = 'train_with_activity_score.csv'  # Replace with your actual cleaned dataset file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "###the carb list\n",
    "carbs_cols = [col for col in df.columns if col.startswith('carbs-')]\n",
    "\n",
    "##replacing the nan or blank by 0 as it is giving error in the EDA \n",
    "df[carbs_cols] = df[carbs_cols].fillna(0)\n",
    "\n",
    "### instead of 5 min i am doing the total cab value for the 15 minute interval to reduce the features\n",
    "for i in range(0, len(carbs_cols), 3):\n",
    "    # Create the new column name for the 15-minute interval\n",
    "    new_col_name = f'carbs_{carbs_cols[i]}_to_{carbs_cols[i+2]}'\n",
    "    \n",
    "    # Sum the values of three consecutive columns to represent a 15-minute interval\n",
    "    df[new_col_name] = df[carbs_cols[i]] + df[carbs_cols[i+1]] + df[carbs_cols[i+2]]\n",
    "\n",
    "#drop original carbss\n",
    "df.drop(columns=carbs_cols, inplace=True)\n",
    "\n",
    "#updated DataFrame\n",
    "df.to_csv('train_with_15_min_carbs_intervals.csv', index=False)\n",
    "\n",
    "#verify if there is anything or any error\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "####the df from the last preprocessing step\n",
    "import pandas as pd\n",
    "\n",
    "#cleaned dataset upto now\n",
    "file_path = 'train_with_15_min_carbs_intervals.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "### similarly the calorie to 15 minute interval instead of 5 minute interval\n",
    "## i am using the same function\n",
    "\n",
    "def aggregate_to_15_min_intervals(df, column_prefix):\n",
    "    \n",
    "    cols = [col for col in df.columns if col.startswith(column_prefix)]\n",
    "    \n",
    "    ###nan and empty by 0\n",
    "    df[cols] = df[cols].fillna(0)\n",
    "    \n",
    "    # grouping\n",
    "    for i in range(0, len(cols), 3):\n",
    "        ## 15 interval from 5\n",
    "        new_col_name = f'{column_prefix}_from_{cols[i]}_to_{cols[i+2]}'\n",
    "        \n",
    "        # now i will get the total carb in those columns \n",
    "        df[new_col_name] = df[cols[i]] + df[cols[i+1]] + df[cols[i+2]]\n",
    "    \n",
    "    #drop original 5 min interval columns, so droping the regular 72 \n",
    "    df.drop(columns=cols, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# cal columns aggreg\n",
    "df = aggregate_to_15_min_intervals(df, 'cals')\n",
    "\n",
    "# similarly for the steps to get total steps before the blood glucose at 0:00\n",
    "df = aggregate_to_15_min_intervals(df, 'steps')\n",
    "\n",
    "###new CSV file\n",
    "df.to_csv('train_with_15_min_intervals_cals_steps.csv', index=False)\n",
    "\n",
    "#### lets verify \n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# ## latest cleaned dataset \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_path = 'train_with_15_min_intervals_cals_steps.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ### bg columns\n",
    "bg_cols = [col for col in df.columns if col.startswith('bg-')]\n",
    "\n",
    "### Function to impute missing values ###\n",
    "def impute_bg_values(row, bg_cols):\n",
    "    # fforward fill: Handle the first few columns by propagating forward the next available value\n",
    "    if pd.isna(row[bg_cols[0]]):  # check point: the first column is NaN\n",
    "        for i in range(1, len(bg_cols)):\n",
    "            if not pd.isna(row[bg_cols[i]]):\n",
    "                row[bg_cols[0]] = row[bg_cols[i]]\n",
    "                break\n",
    "    \n",
    "    ##looping through each bg column (starting from the second one)\n",
    "    for i in range(1, len(bg_cols)):\n",
    "        if pd.isna(row[bg_cols[i]]):\n",
    "            if i == len(bg_cols) - 1:\n",
    "                #### last column: Impute with the previous column's value\n",
    "                row[bg_cols[i]] = row[bg_cols[i-1]]\n",
    "            else:\n",
    "                ###all the middle : impute with the mean of the previous and next column\n",
    "                if not pd.isna(row[bg_cols[i-1]]) and not pd.isna(row[bg_cols[i+1]]):\n",
    "                    row[bg_cols[i]] = (row[bg_cols[i-1]] + row[bg_cols[i+1]]) / 2\n",
    "                elif not pd.isna(row[bg_cols[i-1]]):\n",
    "                    row[bg_cols[i]] = row[bg_cols[i-1]]\n",
    "                elif not pd.isna(row[bg_cols[i+1]]):\n",
    "                    row[bg_cols[i]] = row[bg_cols[i+1]]\n",
    "    \n",
    "    return row\n",
    "\n",
    "#lets execute the impute fun \n",
    "df = df.apply(lambda row: impute_bg_values(row, bg_cols), axis=1)\n",
    "\n",
    "### just checking the df if there is any missing \n",
    "missing_values_count = df[bg_cols].isnull().sum()\n",
    "print(missing_values_count)\n",
    "\n",
    "####  UPDATED DF \n",
    "df.to_csv('train_with_imputed_bg_final_corrected.csv', index=False)\n",
    "\n",
    "df[bg_cols].isnull().sum().sum()\n",
    "df\n",
    "import pandas as pd\n",
    "\n",
    "#latest dataset\n",
    "file_path = 'train_with_imputed_bg_final_corrected.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "###now lets work on the  hr columns\n",
    "hr_cols = [col for col in df.columns if col.startswith('hr-')]\n",
    "\n",
    "#fillling NaN values with the mean of the column for each hr column\n",
    "df[hr_cols] = df[hr_cols].fillna(df[hr_cols].mean())\n",
    "\n",
    "### updated Data_Frame\n",
    "df.to_csv('train_with_imputed_hr_final_mean.csv', index=False)\n",
    "\n",
    "### any remaining missing values\n",
    "missing_values_count = df[hr_cols].isnull().sum()\n",
    "print(missing_values_count)\n",
    "\n",
    "### just to verify the changes\n",
    "print(df[hr_cols].head())\n",
    "\n",
    "\n",
    "df[hr_cols].isnull().sum().sum()\n",
    "\n",
    "df\n",
    "import pandas as pd\n",
    "\n",
    "### latest cleaned dataset\n",
    "file_path = 'train_with_imputed_hr_final_mean.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "## insuling cols 72 cols \n",
    "insulin_cols = [col for col in df.columns if col.startswith('insulin-')]\n",
    "\n",
    "### missing values in insulin columns\n",
    "missing_values_insulin = df[insulin_cols].isnull().sum()\n",
    "\n",
    "## count of the missing in insulin \n",
    "print(missing_values_insulin)\n",
    "\n",
    "### ok total miss \n",
    "total_missing_insulin = missing_values_insulin.sum()\n",
    "print(f\"Total missing values in insulin columns: {total_missing_insulin}\")\n",
    "\n",
    "\n",
    "\n",
    "# latest df same before the explore on the missing vals \n",
    "file_path = 'train_with_imputed_bg_final_corrected.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "### insulin columns  \n",
    "insulin_cols = [col for col in df.columns if col.startswith('insulin-')]\n",
    "\n",
    "# impute function missing values for insulin columns row-wise\n",
    "def impute_insulin_values(row, insulin_cols):\n",
    "    ### copy to put it back \n",
    "    row_insulin = row[insulin_cols].copy()\n",
    "\n",
    "    ### missing values at the beginning (forward fill)\n",
    "    first_valid_index = row_insulin.first_valid_index()\n",
    "    if first_valid_index is not None:\n",
    "        first_valid_index_loc = insulin_cols.index(first_valid_index)\n",
    "        if first_valid_index_loc > 0:\n",
    "            row_insulin.iloc[:first_valid_index_loc] = row_insulin.iloc[first_valid_index_loc]\n",
    "\n",
    "    #missing values at the end (backward fill)\n",
    "    last_valid_index = row_insulin.last_valid_index()\n",
    "    if last_valid_index is not None:\n",
    "        last_valid_index_loc = insulin_cols.index(last_valid_index)\n",
    "        if last_valid_index_loc < len(row_insulin) - 1:\n",
    "            row_insulin.iloc[last_valid_index_loc + 1:] = row_insulin.iloc[last_valid_index_loc]\n",
    "\n",
    "    #  ## interpolate missing values in between\n",
    "    row_insulin.interpolate(method='linear', inplace=True)\n",
    "\n",
    "    return row_insulin\n",
    "\n",
    "## row-wise imputation function to each row\n",
    "df[insulin_cols] = df.apply(lambda row: impute_insulin_values(row, insulin_cols), axis=1)\n",
    "\n",
    "# # handle the case where an entire row of insulin values is missing\n",
    "def column_mean_imputation(df, insulin_cols):\n",
    "    for col in insulin_cols:\n",
    "        # indices where the entire row is missing\n",
    "        missing_indices = df[df[col].isnull()].index\n",
    "        \n",
    "        for idx in missing_indices:\n",
    "            # mean of 20 rows above and 20 rows below the missing row, if they exist\n",
    "            start_idx = max(0, idx - 20)\n",
    "            end_idx = min(len(df), idx + 20)\n",
    "            \n",
    "            # mean of the specified range, excluding the missing value itself\n",
    "            surrounding_mean = df[col].iloc[start_idx:end_idx].mean()\n",
    "            \n",
    "            # impute the missing value with the surrounding mean\n",
    "            df.at[idx, col] = surrounding_mean\n",
    "\n",
    "# column-wise imputation for rows that are entirely missing\n",
    "column_mean_imputation(df, insulin_cols)\n",
    "\n",
    "# # just if there are any remaining missing values\n",
    "missing_values_count = df[insulin_cols].isnull().sum()\n",
    "print(\"Remaining missing values after imputation:\", missing_values_count)\n",
    "\n",
    "#updated DataFrame\n",
    "df.to_csv('train_with_imputed_insulin_final_corrected_1.csv', index=False)\n",
    "\n",
    "# irst few rows to verify the changes\n",
    "print(df[insulin_cols].head())\n",
    "\n",
    "print(df[insulin_cols].mean())\n",
    "import pandas as pd\n",
    "\n",
    "#atest dataset\n",
    "file_path = 'train_with_imputed_insulin_final_corrected_1.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# hr columns\n",
    "hr_cols = [col for col in df.columns if col.startswith('hr-')]\n",
    "\n",
    "#NaN values with the mean of the column for each hr column\n",
    "df[hr_cols] = df[hr_cols].fillna(df[hr_cols].mean())\n",
    "\n",
    "# updated DataFrame\n",
    "df.to_csv('train_preprocessed.csv', index=False)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "missing_values_count = df[hr_cols].isnull().sum()\n",
    "print(missing_values_count)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(df[hr_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906e235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
