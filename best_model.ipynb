{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abccbb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 62\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Perform RandomizedSearchCV with return_train_score enabled\u001b[39;00m\n\u001b[1;32m     59\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     60\u001b[0m     xgb, param_distributions\u001b[38;5;241m=\u001b[39mparam_dist, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     61\u001b[0m )\n\u001b[0;32m---> 62\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Extract results from the random search\u001b[39;00m\n\u001b[1;32m     65\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(random_search\u001b[38;5;241m.\u001b[39mcv_results_)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1961\u001b[0m         ParameterSampler(\n\u001b[1;32m   1962\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1963\u001b[0m         )\n\u001b[1;32m   1964\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m         clone(base_estimator),\n\u001b[1;32m    968\u001b[0m         X,\n\u001b[1;32m    969\u001b[0m         y,\n\u001b[1;32m    970\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    971\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    972\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    973\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    974\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m )\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/apps/eb/Anaconda3/2023.09-0/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/apps/eb/Anaconda3/2023.09-0/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/apps/eb/Anaconda3/2023.09-0/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/apps/eb/Anaconda3/2023.09-0/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/apps/eb/Anaconda3/2023.09-0/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "###libraries that i can remember, adding as i work \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# directory to save outputs\n",
    "output_dir = \"best_model_outputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#DATA FROM PREPROCESSING \n",
    "df = pd.read_csv('train_preprocessed.csv')  \n",
    "\n",
    "# converting th e  time column to seconds\n",
    "def time_to_seconds(time_str):\n",
    "    try:\n",
    "        h, m, s = map(int, time_str.split(':'))\n",
    "    except ValueError:\n",
    "        h, m = map(int, time_str.split(':'))\n",
    "        s = 0\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "df['time_seconds'] = df['time'].apply(time_to_seconds)  \n",
    "\n",
    "# # features and target separation, since I change the name of bg to target during the preprocessing\n",
    "X = df.drop(columns=['p_num', 'id', 'target', 'time'])  \n",
    "X['time_seconds'] = df['time_seconds']  \n",
    "y = df['target']  \n",
    "\n",
    "### apply PCA to extract top 5 components\n",
    "pca = PCA(n_components=5, random_state=123)\n",
    "pca_components = pca.fit_transform(X)\n",
    "pca_df = pd.DataFrame(pca_components, columns=[f'PC{i+1}' for i in range(5)])\n",
    "\n",
    "# ## combine the top 5 PCs with the remaining original features\n",
    "X_combined = pd.concat([X, pca_df], axis=1)\n",
    "\n",
    "# train test split  (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# parameter grid for the randomsearch \n",
    "param_dist = {\n",
    "    'max_depth': np.arange(1, 50),  # max_depth values for XGBoost\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),  # Learning rate for XGBoost\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  # Number of trees\n",
    "    'subsample': np.linspace(0.5, 1.0, 5),  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': np.linspace(0.5, 1.0, 5)  # Subsample ratio of columns\n",
    "}\n",
    "\n",
    "# ## XGBoost model\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "#  randomizedSearchCV with return_train_score enabled\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb, param_distributions=param_dist, n_iter=50, scoring='r2', cv=5, random_state=42, n_jobs=-1, return_train_score=True\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# results from the random search\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# R-squared vs max_depth for train and test\n",
    "train_scores_depth = []\n",
    "test_scores_depth = []\n",
    "depth_values = results['param_max_depth'].unique()\n",
    "\n",
    "for depth in depth_values:\n",
    "    subset = results[results['param_max_depth'] == depth]\n",
    "    train_scores_depth.append(subset['mean_train_score'].mean())\n",
    "    test_scores_depth.append(subset['mean_test_score'].mean())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depth_values, train_scores_depth, label=\"Train R-squared\", marker='o')\n",
    "plt.plot(depth_values, test_scores_depth, label=\"Test R-squared\", marker='o')\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"R-squared\")\n",
    "plt.title(\"R-squared vs Max Depth (Random Search with Top 5 PCs + Original Features, XGBoost)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(output_dir, \"r_squared_vs_max_depth_random_search_xgboost_combined.png\"))\n",
    "plt.close()\n",
    "\n",
    "# R-squared vs colsample_bytree for train and test\n",
    "train_scores_features = []\n",
    "test_scores_features = []\n",
    "features_values = results['param_colsample_bytree'].unique()\n",
    "\n",
    "for colsample in features_values:\n",
    "    subset = results[results['param_colsample_bytree'] == colsample]\n",
    "    train_scores_features.append(subset['mean_train_score'].mean())\n",
    "    test_scores_features.append(subset['mean_test_score'].mean())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(features_values, train_scores_features, label=\"Train R-squared\", marker='o')\n",
    "plt.plot(features_values, test_scores_features, label=\"Test R-squared\", marker='o')\n",
    "plt.xlabel(\"Colsample by Tree\")\n",
    "plt.ylabel(\"R-squared\")\n",
    "plt.title(\"R-squared vs Colsample by Tree (Random Search with Top 5 PCs + Original Features, XGBoost)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(output_dir, \"r_squared_vs_colsample_bytree_random_search_xgboost_combined.png\"))\n",
    "plt.close()\n",
    "\n",
    "# best model from random search\n",
    "best_model = random_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Best model test set score:\", test_score)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = os.path.join(output_dir, \"best_model.pkl\")\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "#final test set score to a text file\n",
    "score_filename = os.path.join(output_dir, \"best_model_score.txt\")\n",
    "with open(score_filename, 'w') as score_file:\n",
    "    score_file.write(f\"Best model test set score: {test_score}\\n\")\n",
    "\n",
    "# ## just checking the importance in the ascendingg\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X_combined.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "feature_importances_filename = os.path.join(output_dir, \"feature_importances_best_model.csv\")\n",
    "feature_importances.to_csv(feature_importances_filename, index=False)\n",
    "\n",
    "print(f\"Model, score, and feature importances saved in {output_dir}.\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# PCA model to the output directory\n",
    "pca_filename = os.path.join(output_dir, \"best_model_pca.pkl\")\n",
    "with open(pca_filename, 'wb') as pca_file:\n",
    "    pickle.dump(pca, pca_file)\n",
    "\n",
    "print(f\"PCA model saved as {pca_filename}.\")\n",
    "\n",
    "\n",
    "##lets also add the pkl files for pca and the model to the current dir too\n",
    "with open(\"best_model.pkl\", 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "with open(\"best_model_pca.pkl\", 'wb') as pca_file:\n",
    "    pickle.dump(pca, pca_file)\n",
    "\n",
    "print(f\"Model and PCA saved in both {output_dir} and the working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5aa2387",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m pca_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pca_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pca_file:\n\u001b[0;32m---> 12\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(pca, pca_file)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA model saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpca_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pca' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730985d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
